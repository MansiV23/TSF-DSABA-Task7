{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install 'scikit-learn==0.24.0' # Have to use this version of scikit-learn, for mean_absolute_error \n\nimport pandas as pd\nimport numpy as np\nfrom numpy import concatenate\nfrom math import sqrt\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use(\"fivethirtyeight\")\n%matplotlib inline\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\nfrom textblob import TextBlob\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"id":"6v4r-UC33DFm","outputId":"8cc5a0fb-a430-40ed-f020-c4023d0f7807","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prices = pd.read_csv('../input/smp-dataset/BSESN.csv')\ndf_prices","metadata":{"id":"4EUxdUEnEeeJ","outputId":"9f88653f-10d4-427d-a38a-eec656123fed","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['Date','Category','News']\ndf_news = pd.read_csv('../input/smp-dataset/indianewsheadlines.csv', names = cols)\ndf_news = df_news.dropna(axis = 0, how ='any') \ndf_news","metadata":{"id":"FPIr2r4QdRGu","outputId":"27d94e5c-a440-465d-f1b9-1b82e094ad42","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cleaning and Pre-processing the data:","metadata":{"id":"suUYrOj7bHi3"}},{"cell_type":"code","source":"# Dropping 0 values, and the Category column as we don't require this for our analysis.\ndf_news.drop(0, inplace=True)\ndf_news.drop('Category', axis = 1, inplace=True)","metadata":{"id":"Tp3NSpsgeMib","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting 'Date' columns from both our dataframes to type datetime\ndf_news['Date'] = pd.to_datetime(df_news['Date'],format= '%Y%m%d')\ndf_prices['Date'] = pd.to_datetime(df_prices['Date'])\ndf_prices\n","metadata":{"id":"PVowb1Qm2ezi","outputId":"784dcee0-af3f-44ee-9ae5-e565a1a5806c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_news['News'] = df_news.groupby(['Date']).transform(lambda x : ' '.join(x)) \ndf_news = df_news.drop_duplicates() \ndf_news.reset_index(inplace = True, drop = True)\ndf_news","metadata":{"id":"qzI3u7KJ2lVP","outputId":"b54412ac-630b-426f-d93e-877e00c9bc71","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cleaning headlines\nc = []\n\nfor i in range(0,len(df_news['News'])):\n    news = re.sub('[^a-zA-Z]',' ',df_news['News'][i])\n    news = news.lower()\n    news = news.split()\n    news = [ps.stem(word) for word in news if not word in set(stopwords.words('english'))]\n    print(i)\n    news=' '.join(news)\n    c.append(news)    \n    # news = [word for word in news if word not in set(stopwords.words('english'))]\n    # print(news)\n    # news = []\n    # for w in news: news.append(ps.stem(w))\n    # print(news)\n    # news=' '.join(news)\n    # print(news)\n    # c.append(news)","metadata":{"id":"4jxMFBGx2qJw","outputId":"848d478a-9a5b-4b90-d7ab-edcc6581b276","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_news['News'] = pd.Series(c)\ndf_news","metadata":{"id":"80NywnJy2q6u","outputId":"559b787d-bcbf-4a5e-8f95-bab03f8dcac2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculating Subjectivity and Polarity scores using TextBlob module:","metadata":{"id":"bGKd6qvAcIUh"}},{"cell_type":"code","source":"#Functions to get the subjectivity and polarity\ndef getSubjectivity(text):\n  return TextBlob(text).sentiment.subjectivity\n\ndef getPolarity(text):\n  return  TextBlob(text).sentiment.polarity","metadata":{"id":"9o0yogHo221J","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding subjectivity and polarity columns\ndf_news['Subjectivity'] = df_news['News'].apply(getSubjectivity)\ndf_news['Polarity'] = df_news['News'].apply(getPolarity)\ndf_news","metadata":{"id":"oHeo3Wgd24i5","outputId":"54afd952-3a5f-4096-f1b5-6ad9626494a5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Carrying out Sentimental Analysis on the News Headlines:","metadata":{"id":"rArXz_sXcZvR"}},{"cell_type":"code","source":"#Adding sentiment score to df_news\nsia = SentimentIntensityAnalyzer()\n\ndf_news['Compound'] = [sia.polarity_scores(v)['compound'] for v in df_news['News']]\ndf_news['Negative'] = [sia.polarity_scores(v)['neg'] for v in df_news['News']]\ndf_news['Neutral'] = [sia.polarity_scores(v)['neu'] for v in df_news['News']]\ndf_news['Positive'] = [sia.polarity_scores(v)['pos'] for v in df_news['News']]\ndf_news","metadata":{"id":"fkaiMxwe3K09","outputId":"aafa789e-fe66-4b17-fccd-c328d8c49199","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging our findings (the updated News dataframe) with the Prices dataframe\ndf_merge = pd.merge(df_prices, df_news, how='inner', on='Date')\nprint(df_prices)\ndf_merge.drop('Date', axis = 1, inplace=True)\ndf_merge.drop('News', axis=1, inplace=True)\nprint(df_merge.columns)\nprint(len(df_merge))\nprint(len(df_prices))\nprint(len(df_news))","metadata":{"id":"3W4nk2yc3LE4","outputId":"97cb65d6-b510-46b3-c4bc-9fd27181032f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting our data series ready for Multivariate Time Series Forecasting\nfrom pandas import DataFrame as df\nfrom pandas import concat\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n\tn_vars = 1 if type(data) is list else data.shape[1]\n\tdf1 = df(data)\n\tcols, names = list(), list()\n\t# input sequence (t-n, ... t-1)\n\tfor i in range(n_in, 0, -1):\n\t\tcols.append(df1.shift(i))\n\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n\t# forecast sequence (t, t+1, ... t+n)\n\tfor i in range(0, n_out):\n\t\tcols.append(df1.shift(-i))\n\t\tif i == 0:\n\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n\t\telse:\n\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n\t# put it all together\n\tagg = concat(cols, axis=1)\n\tagg.columns = names\n\t# drop rows with NaN values\n\tif dropnan:\n\t\tagg.dropna(inplace=True)\n\treturn agg","metadata":{"id":"ecrFu9_yTHtH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale our data for optimal performance\nvalues = df_merge.values\nprint(df_merge)\nprint(values)\nvalues = values.astype('float32')\n# normalize features\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled = scaler.fit_transform(values)\n# frame as supervised learning\nreframed = series_to_supervised(scaled, 1, 1)\n# drop columns we don't want to predict\nreframed.drop(reframed.columns[[12,13,14,16,17,18,19,20,21,22,23]], axis=1, inplace=True)\nprint(reframed.columns)","metadata":{"id":"WfBvsX8mTM1p","outputId":"1a6b161d-7580-43a2-8fca-1789a733eef9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building a **LSTM** **(Long Short Term Memory)** Model to predict Stock Prices:","metadata":{"id":"6lnHts6uqgrD"}},{"cell_type":"code","source":"# design the network\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\nmodel = Sequential()\nmodel.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(loss='mae', optimizer='adam') \n\n# fit network\nhistory = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n\n# plot history\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()","metadata":{"id":"W0JIAPYrYbVc","outputId":"02b392b6-e337-497e-cc19-518b1f3802bf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split into train and test sets\nvalues = reframed.values\nprint((values).shape)\nn_train_hours = 90\ntrain = values[:n_train_hours, :]\ntest = values[n_train_hours:, :]\n# split into input and outputs\ntrain_X, train_y = train[:, :-1], train[:, -1]\ntest_X, test_y = test[:, :-1], test[:, -1]\n# reshape input to be 3D [samples, timesteps, features]\ntrain_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\ntest_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)","metadata":{"id":"ze9mGTcBYaxM","outputId":"cdd4f22d-fd65-4301-f2f8-3d405c52bd9c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Testing** the LSTM Model with the test data and calculating **RMSE(Root Mean Square Error)**:","metadata":{"id":"zsIZJGe6q8yp"}},{"cell_type":"code","source":"# make a prediction\nprint(test_X.shape)\ntest_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[2]))\nprint(test_X.shape)\nyhat = model.predict(test_X)\ntest_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n# invert scaling for forecast\ninv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)\ninv_yhat = inv_yhat[:,0]\n# invert scaling for actual\ntest_y = test_y.reshape((len(test_y), 1))\ninv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\ninv_y = scaler.inverse_transform(inv_y)\ninv_y = inv_y[:,0]\n# calculate RMSE\nrmse = sqrt(mean_squared_error(inv_y, inv_yhat))\nprint('Test RMSE: %.3f' % rmse)\n","metadata":{"id":"JQxDeAx8Ybin","outputId":"5e2de18d-a9dd-4816-9650-b8e76d41a009","trusted":true},"execution_count":null,"outputs":[]}]}